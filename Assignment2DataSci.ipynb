{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>COMP 47670 Assignment 2 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Brian Delaney - 09513574 </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Required Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Q1 - Select Two Review Categories and Scrape</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Website Base Address</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_address = \"http://mlg.ucd.ie/modules/yalp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generic Cleaning Functions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Set up the required downloads for cleaning the data - we can call this straight away</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Brian\n",
      "[nltk_data]     Delaney\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Brian\n",
      "[nltk_data]     Delaney\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def setup_clean():\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "setup_clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Take a raw text string and tokenize it using the nlkt word tokenizer</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(rawtext):\n",
    "    return nltk.word_tokenize(rawtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Normalise are tokens by making them all lowercase</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(tokens):\n",
    "    normalised = []\n",
    "    for token in tokens:\n",
    "        normalised.append(token.lower())\n",
    "    return normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Remove the standard english stop words using the built in nlkt stop words list</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(tokens):\n",
    "    stopwds = stopwords.words('english')\n",
    "    removed = []\n",
    "    [removed.append(token) for token in tokens if token not in stopwds]\n",
    "    return removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Stem our words using nltk porter stemmer to further be able to extract meaning from the words</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(tokens):\n",
    "    stemmed = []\n",
    "    stemmer = PorterStemmer()\n",
    "    [stemmed.append(stemmer.stem(word)) for word in tokens]\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Define a cleaning pipeline using our cleaning functions that takes some raw text and returns a list of cleaned tokens</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(raw_text):\n",
    "    tokens = tokenise(raw_text)\n",
    "    tokens = normalise(tokens)\n",
    "    tokens = removeStopWords(tokens)\n",
    "    tokens = stem(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generic Scraping Functions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Return Content of Page using requests lib</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        if(r.status_code == 200):\n",
    "            return r.content\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Error Scraping {0} : {1}\".format(url, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scrape the location links for a given location type given the base page soup </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_location_links(soup):\n",
    "    location_links = soup.find_all('a')\n",
    "\n",
    "    full_location_links = []\n",
    "    for location_link in location_links:\n",
    "        full_location_link = base_address + location_link['href']\n",
    "        full_location_links.append(full_location_link)\n",
    "\n",
    "    return full_location_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scrape the reviews for a given location link </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews_for_location_link(location_link):\n",
    "    content = get_page(location_link)\n",
    "    soup = BeautifulSoup(content, features='html.parser')\n",
    "\n",
    "    all_reviews = []\n",
    "    reviews = soup.find_all('div', 'review')\n",
    "    for review in reviews:\n",
    "        review_data = extract_review_data(review)\n",
    "        all_reviews.append(review_data)\n",
    "\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Extract the review score from the stars image using regular expressiosn</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_review_score_from_image(review_score_img):\n",
    "    return re.findall(r'stars-([0-9]).png', review_score_img['src'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Convert the numeric star rating into a positive (1) or negative (0) review</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_stars_to_postive_or_negative(num_stars):\n",
    "    num_stars = int(num_stars)\n",
    "    if(num_stars > 0 and num_stars <= 3):\n",
    "        return 0\n",
    "    elif(num_stars > 3 and num_stars <= 5):\n",
    "        return 1\n",
    "    else:\n",
    "        raise Exception(\"Invalid Review Rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Extract the review data from the review page soup </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_review_data(review_soup):\n",
    "    review_text = review_soup.find('p', 'text').getText()\n",
    "    review_score_img = review_soup.find('img')\n",
    "\n",
    "    review_score = extract_review_score_from_image(review_score_img)\n",
    "    review_class = num_stars_to_postive_or_negative(review_score)\n",
    "\n",
    "    return {\"review_class\" : review_class, \"review_text\" : review_text}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Function that when given a base type page will scrape the review data, clean the review and return a list of dicts.\n",
    "Each dict has a \"review_class\" representing whether the review was positive or negative and a \"review_text\" which\n",
    "represents a cleaned list of tokens from the review.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_review_data(start_page):\n",
    "    content = get_page(start_page)\n",
    "    soup = BeautifulSoup(content, features='html.parser')\n",
    "    location_links = scrape_location_links(soup)\n",
    "\n",
    "    all_reviews_for_type = []\n",
    "    for location_link in location_links:\n",
    "        all_review_data_for_location = scrape_reviews_for_location_link(location_link)\n",
    "        for review_data in all_review_data_for_location:\n",
    "            cleaned_review_text = clean_text(review_data[\"review_text\"])\n",
    "            all_reviews_for_type.append({\"review_class\" : review_data[\"review_class\"], \"review_text\": cleaned_review_text})\n",
    "\n",
    "    return all_reviews_for_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Start Scrape and Clean </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_start_page = \"http://mlg.ucd.ie/modules/yalp/bars_list.html\"\n",
    "restaurant_start_page = \"http://mlg.ucd.ie/modules/yalp/restaurants_list.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_bar_data = get_and_clean_review_data(bar_start_page)\n",
    "cleaned_restaurant_data = get_and_clean_review_data(restaurant_start_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Q2 - Create numeric represntitons, train classifier and evaluate</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Category 1 - Bars</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Sperate out bar data into category and review content lists</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_classes = []\n",
    "review_text = []\n",
    "\n",
    "for cleaned_data in cleaned_bar_data:\n",
    "    review_text.append(cleaned_data[\"review_text\"])\n",
    "    review_classes.append(cleaned_data[\"review_class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create tfidf_vectorizor and arrange our data in the correct numeric format </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(preprocessor=' '.join, stop_words='english')\n",
    "\n",
    "y = np.array(review_classes)\n",
    "X = tfidf.fit_transform(review_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460,)\n",
      "(1460, 7005)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Split our data into train and test sets and train a RandomForest Ensemble Classifier on the training set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Evaluate using test set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 62  42]\n",
      " [  9 179]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.60      0.71       104\n",
      "           1       0.81      0.95      0.88       188\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       292\n",
      "   macro avg       0.84      0.77      0.79       292\n",
      "weighted avg       0.83      0.83      0.82       292\n",
      "\n",
      "0.8253424657534246\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Evaluate using cross validation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9047619  0.84353741 0.82993197 0.7414966  0.82312925 0.86206897\n",
      " 0.84137931 0.84137931 0.8        0.84137931]\n",
      "0.8329064039408868  =/-  0.04201200978068417\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(classifier, X, y, cv=10)\n",
    "print(scores)\n",
    "scores = pd.Series(scores)\n",
    "print(scores.mean(), \" =/- \", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Category 2 - Restaurants</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Sperate out bar data into category and review content lists</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_classes = []\n",
    "review_text = []\n",
    "\n",
    "for cleaned_data in cleaned_restaurant_data:\n",
    "    review_text.append(cleaned_data[\"review_text\"])\n",
    "    review_classes.append(cleaned_data[\"review_class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create tfidf_vectorizor and arrange our data in the correct numeric format </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(preprocessor=' '.join, stop_words='english')\n",
    "\n",
    "y = np.array(review_classes)\n",
    "X = tfidf.fit_transform(review_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440,)\n",
      "(1440, 6485)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Split our data into train and test sets and train a RandomForest Ensemble Classifier on the training set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Evaluate using test set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56  36]\n",
      " [  9 187]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.61      0.71        92\n",
      "           1       0.84      0.95      0.89       196\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       288\n",
      "   macro avg       0.85      0.78      0.80       288\n",
      "weighted avg       0.85      0.84      0.84       288\n",
      "\n",
      "0.84375\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Evaluate using cross validation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83448276 0.77241379 0.8137931  0.84027778 0.84722222 0.84722222\n",
      " 0.81944444 0.7972028  0.76223776 0.85314685]\n",
      "0.8187443734426493  =/-  0.03222396466328304\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(classifier, X, y, cv=10)\n",
    "print(scores)\n",
    "scores = pd.Series(scores)\n",
    "print(scores.mean(), \" =/- \", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Q3 - Evaluate how well the classifiers transfer between categories</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "1440\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_bar_data))\n",
    "print(len(cleaned_restaurant_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Combine data into a single data set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = []\n",
    "\n",
    "for cleaned_bar in cleaned_bar_data:\n",
    "    cleaned_data.append(cleaned_bar)\n",
    "    \n",
    "for cleaned_restaurant in cleaned_restaurant_data:\n",
    "    cleaned_data.append(cleaned_restaurant)\n",
    "    \n",
    "print(len(cleaned_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Split the data into target values and review content as before</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_classes = []\n",
    "review_text = []\n",
    "\n",
    "for data in cleaned_data:\n",
    "    review_text.append(data[\"review_text\"])\n",
    "    review_classes.append(data[\"review_class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create numeric tfidf representation of our data set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(preprocessor=' '.join, stop_words='english')\n",
    "\n",
    "y = np.array(review_classes)\n",
    "X = tfidf.fit_transform(review_text).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train model A using only the first 1460 reviews i.e. only the bar data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bar = X[:1460]\n",
    "y_bar = y[:1460]\n",
    "\n",
    "bar_classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "bar_classifier.fit(X_bar, y_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train model A using only the last 1440 reviews i.e. only the restaurant data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_restaurant = X[1440:]\n",
    "y_restaurant = y[1440:]\n",
    "\n",
    "restaurant_classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "restaurant_classifier.fit(X_restaurant, y_restaurant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Test the performance of the bar reviews on the classifier trained on the restaurant data only </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[326 239]\n",
      " [ 28 867]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.58      0.71       565\n",
      "           1       0.78      0.97      0.87       895\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1460\n",
      "   macro avg       0.85      0.77      0.79      1460\n",
      "weighted avg       0.84      0.82      0.81      1460\n",
      "\n",
      "0.8171232876712329\n"
     ]
    }
   ],
   "source": [
    "y_bar_pred = restaurant_classifier.predict(X_bar)\n",
    "\n",
    "print(confusion_matrix(y_bar, y_bar_pred))\n",
    "print(classification_report(y_bar, y_bar_pred))\n",
    "print(accuracy_score(y_bar, y_bar_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Test the performance of the restaurant reviews on the classifier trained on the bar data only </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[324 188]\n",
      " [ 47 901]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.63      0.73       512\n",
      "           1       0.83      0.95      0.88       948\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1460\n",
      "   macro avg       0.85      0.79      0.81      1460\n",
      "weighted avg       0.84      0.84      0.83      1460\n",
      "\n",
      "0.839041095890411\n"
     ]
    }
   ],
   "source": [
    "y_rest_pred = bar_classifier.predict(X_restaurant)\n",
    "\n",
    "print(confusion_matrix(y_restaurant, y_rest_pred))\n",
    "print(classification_report(y_restaurant, y_rest_pred))\n",
    "print(accuracy_score(y_restaurant, y_rest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
